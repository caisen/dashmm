THIS BRANCH TODO

TODO: clean up code where possible
TODO: create test case for new ViewSet stuff? Or just do the real thing and
      have done with it.

TODO: decide if I want to add assertions around the calls to the Expansion
      operations to make sure the Expansion Role is correct.

TODO: Look at TODO in the code, and address where possible
TODO: We are pretty inconsistent about the use of int vs size_t. Work out what
      to do about this.
          Basically, leave it better than you found it.
TODO: Improve the way that we optionally put out the DAG information. Perhaps
      this would be another version of evaluate, but which takes an additional
      template parameter serving the DAG output. This would then force the
      factorization of evaluate even higher.
        Or perhaps once there is a mechanism to get the DAG for a given
        evaluation, we can just go ahead and return that the user, and they
        can call whatever methods they want on it.
TODO: create standard regression and performance testing script to determine
      quality of a build.
TODO: Decide if we should move setup_termination_detection, setup_edge_lists
      and destroy_DAG_LCOs into evaluator

TODO: Can we skip the laplace_sph_precompute thing? Or rather, put it into the
      constructor in some way?
        (This is related to another step we need to take in the near future.
         That being said, this might be solved automatically once we implement
         that feature.)



Overall Plan to 1.0

 * DONE Split DAG from Tree

 * Full distribution of data and work
    - build one locality tree from distributed particle data (and sort those
      particles as needed)
    - Array needs to be updated accordingly
    - Introduce more distribution policies
 * Kernel Parameters and Table generation
 * Make intermediate expansions possible
 * Split Evaluate into pieces and expose more interface to users
    - Enable repeat use of a DAG
    - Potentially provide objects representing the tree and so on to the user
      and some utility routines to use the resulting objects
 * Finish interface
    - Make it so that an advanced user could call all the needed stuff directly
      from an HPX thread.
 * Documentation clean up throughout
    - advanced user guide; including how to define methods
    - be sure to be clear about routines callable from HPX or not.
    - actually build the documentation with DoxyGen to see if it is done
    - consider placing the user-facing heads into a different directory than
      the internal stuff
 * As there is time, work on performance
    - Time various parts of the code



NOTE: Big problem with the tree construction. We want to build the tree in
      one locality. And so to do that in the old style, this means we need to
      have all the particles in that locality as well. Eventually, we want to
      migrate the particle data to the locations where it is most advantageous.
      So the question is, do we assume that the data is local, or do we instead
      build the tree from distributed particle data.

      Sure, initially we are still doing this for SMP mode, but we want to
      get to where we can do distributed easily. So I want to think about this
      kind of thing along the way.


OPEN QUESTIONS and TODO
TODO: Make the Array type work from inside HPX-5 threads also
        (We have no use case for this just yet. Delay)
TODO: Should we explicitly enforce the singleton nature of Evaluator?
        (This is not a bad idea, but it can wait, as long as the docs warn
         users.)
TODO: currently it is impossible to use the same tree for different Evaluators.
      Do we want to decouple the tree?
        (This might be harder to do. The handles to the DAG make the tree for
         one specific evaluation.)
TODO: Perhaps we want to parameterize the nodes with some user data? So
      the user can use the tree for other things as well.
        (Cool idea; no use case. Delay)
TODO: Do we want to decouple the registration from the evaluation? Two objects?
      Some kind of template function?
        (Not sure. It is not too onerous to do as we have been.)
TODO: There is an overdecomposition factor in ArrayMapAction that is hard
      coded. Explore this and pick one that performs well.




Some notes about issues or future features

* We will need to improve the error handling in this thing quite a bit.
Basically any way that the user-facing methods can go wrong should return
sensible error where possible instead of just being assertions that fail.



Interface Ideas

 * Provide C bindings before too long
      (Useful for people stuck back in the day, but might be of little utility.)

 * We should also in the near term get a base nearest neighbor search. This will
   be essential for SPH and Phil's MFV methods.
   This would be useful in much wider contexts, however.
 * Do LaplaceCOM with softened force (ala GADGET)
 * Do one for Ewald technique for periodic BCs
 * Do one for Short range forces

Some more methods

 * Can we do something more like GADGET's BH method?
    (This is more tricky. The acceptability of an expansion is dependent on the
     particle data of the targets. This would make the node-wide analysis
     harder or more conservative than is needed.)
 * Is there some room for performance improvement in BH where we might use
   single particles for the decision? Is this just a matter of using a smaller
   threshold? Will that pay any dividends?
