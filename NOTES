THIS BRANCH TODO


==========================================
Things that likely would not break the API
==========================================

TODO: Set up code for the inclusion of priorities.
TODO: Change work instigation to be a par-for (or equivalent) over the
      DAG nodes.
        I am not sure we can use the built-in par-for here. If we did, the
        resulting actions would not have the correct priority. I think we
        should give them appropriate priorities. So that is likely a very high
        priority, if not the highest. That way, all the work gets started,
        even at the expense of making progress elsewhere. The runtime cannot
        pick a good schedule without adequate information.

        But if we do not prioritize the spawn, we shall end up with a case
        where the rest of the spawn can be buried under the other work.
        Much better to have it all ready to start.

        So we basically need to collect the spawns into a loop. And then we
        can go ahead and bundle them into groups. The catch is that there will
        be some that are not to be launched. So should we then sort the
        nodes locally, and then spawn? (really just partition them).
TODO: The remote stuff should be an RDMA into a preallocated buffer. At least,
      this would allow a no-copy spawn of the remote edges.

TODO: Decide if the current solution for the DAG vector capacity problem is
      good enough, or if we should instead work toward collecting the tree
      sizes.

TODO: This is likely the big limiter in the short term on problem size. We
      need to improve the memory use of the explicit DAG. If there were a way
      to perhaps clean that up before we really begin the execution that would
      be awesome, or to start to delete it when it begins. But there is a good
      deal of waste and repetition there. The fact of the explicit DAG is nice,
      but it needs to be made more efficient.

TODO: Think about if there are places that RDMA could improve the performance.
      That might have us putting more into the GAS.

TODO: be more clear about when an expansion needs to own data and when not.
TODO: Inside expansionlco.h, we do a forward declaration of DualTree. This seems
      like an inelegant solution, and perhaps one that relies on the
      inclusion order. Check into this.
TODO: targetlco.h: contribute_*_to_T; IN each case there is likely some extra
      copying going on. See if there is a way to reduce that. Perhaps via the
      parcel interface.
TODO: From tree.h line 2240
    // TODO: This is an inelegant solution to the problem of getting the
    // local segments unpinned. src_data and trg_data will unpin the segment
    // when the scope we introduce here is closed. Perhaps add unpin(), but
    // that detracts from the RAII nature of the current ArrayData object.
TODO: Think about the following issue
  The out edge spawn action will have to be ready to either do the current thing,
  or send an action to the remote locality that will first look up the address
  before doing the set. This remote action should continue the result of the
  lookup back to the original LCO where an action will get the user data, and
  update the line in the out edge table inside the LCO.
    NOTE: The return should only happen if the DAG is going to be reused.
          Otherwise, this is overkill.
    NOTE: This creates a possible problem for the termination detection. If the
          LCOs start to get deleted on the last iteration, a return message
          could arrive at a destroyed LCO. This bears some thinking.
TODO: Deal with the return messages about the addresses of the remote LCOs
    (Do we even want to do this? There is an issue with termination detection
     here.)
TODO: Related to the above: If we are not using AGAS, and probably never will,
      is there any reason to bind the expansion data into the LCO? That might
      simplify things quite a bit. It is worth thinking about. We might be
      able to obviate the need for the ViewSet and all of that crap.
TODO: Another thing might be to send this to the tree and not the LCO. Then the
      tree can eventually build up a complete list over the iterations.
      Again, there is a termination problem with this, but it is a different
      perspective.
TODO: clean up code where possible
TODO: In tree, privatize anything possible
TODO: The same is true everywhere I guess.
TODO: We are pretty inconsistent about the use of int vs size_t. Work out what
      to do about this.
          Basically, leave it better than you found it.
        - One place this is annoying is in the 'other_member' member of dag
          nodes. At the moment, we use the larger size there, and case to
          integers for the accuracy.
TODO: create standard regression and performance testing script to determine
      quality of a build.
TODO: Decide if we should also test Hilbert ordering on the top level distrib
      of the tree. This might have some better locality.
TODO: Further, should we allow for a non-space-filling curve distribution.
      This might be a way to make a non-contiguous chunk on the SFC a better
      overall distribution.
TODO: Documentation clean up throughout
    - be sure to be clear about routines callable from HPX or not.
    - actually build the documentation with DoxyGen to see if it is done
TODO: Split Evaluate into pieces and expose more interface to users
    - NOTE: This is not a vital thing to accomplish for 1.0.0
    - Enable repeat use of a DAG
    - Potentially provide objects representing the tree and so on to the user
      and some utility routines to use the resulting objects
TODO: Finish interface
    - NOTE: this is not a vital thing to accomplish for 1.0.0
    - Make it so that an advanced user could call all the needed stuff directly
      from an HPX thread.
    - As a corollary to that, add assertions to routines that have
      inside / outside HPX restrictions
TODO: The expansion concept does not allow for access of the kernel parameters.
   They end up in the table, and cannot be accessed later. Not sure if this is
   a problem, but it could be.
TODO: Another idea from Bo: Store the edges in one place and then just index
      into that. Cuts down on the representation by quite a bit.
TODO: Probably don't save the actual expansion data in the LCO. AGAS is not
      being used, so why protect against it being used in the future.
TODO: FORTRAN skeleten Expansion. Somehow link to a user's existing FORTRAN
      operations.
TODO: Should we explicitly enforce the singleton nature of Evaluator?
        (This is not a bad idea, but it can wait, as long as the docs warn
         users.)

========================================
This that definitely would break the API
========================================


TODO: Make the way that Expansions manage their data not suck as much as it
      does now. Really. There is a strange complicated dance happening with
      all of this, and it will be easy for a user to muck it up.
      -----> NOTE: this will mean breaking changes, and a definite bump to
                   2.0.0.
      -----> NOTE: This seems like we are going to get 2.0.0 by the end of the
                   first grant likely.
TODO: Make S->* static members of Expansion.
        In a complication, there S->M is now not in the pattern of the rest of
        the operators. Not sure what to do about this.
TODO: should we put all the DAG stuff into a namespace DAG? So dashmm::DAG::Edge
      and so on. Extending this, should we do the same thing for other
      subsystems?
        This would be okay, but what would DAG turn into? dag::DAG? That's
        pretty goofy...
TODO: Work out if there is a better way to apply the distribution. We shall
      need to have some way to parallelize it, or have some way to overlap that
      work with other work.
        Perhaps have a second pass with the same sort of tree parallel thing
        like when the DAG is discovered.
TODO: Perhaps we want to parameterize the nodes with some user data? So
      the user can use the tree for other things as well.
  * It would be nice if we were to decouple some of the use of the tree and the
  construction of the tree. The ultimate goal would be to perhaps allow the user
  to supply their tree to us, like if they had a better method to make it, or
  if their code already needs to make a tree for some reason. Then DASHMM could
  just do the DAG and so on. This would also allow us to try other constructions
  more easily. We basically would be able to hot swap implementations. Also,
  this might make it simpler to make a tree that can update adiabadically.
TODO: Should we use exceptions in the main interface to return errors? This is
  probably cleaner. the catch is that I would need to work out what happens
  when I emit an exception in an HPX action.








FUTURE BUILT-INs
 * We should also in the near term get a base nearest neighbor search. This will
   be essential for SPH and Phil's MFV methods.
   This would be useful in much wider contexts, however.
 * Do LaplaceCOM with softened force (ala GADGET)
 * Do one for Ewald technique for periodic BCs
 * Do one for Short range forces
 * Can we do something more like GADGET's BH method?
    (This is more tricky. The acceptability of an expansion is dependent on the
     particle data of the targets. This would make the node-wide analysis
     harder or more conservative than is needed.)
 * Is there some room for performance improvement in BH where we might use
   single particles for the decision? Is this just a matter of using a smaller
   threshold? Will that pay any dividends?



IDEAS TO TRY
  * If we get the tree decoupled from the execution, could we perhaps use
    GADGET or AREPO or GIZMO or whatever to build the tree, and then just sub
    in our execution? That would be a pretty damn good comparison to make.
    It would mean that design of our decoupling would need to be such that
    we could do this. But that would be a really cool comparison to make.
    Really cool.
