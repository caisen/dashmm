The basic idea for the distributed execution:

Bo is working on this bit as a stand alone test case for creating the tree.
We shall likely write up the tree creation scheme and the resulting scaling
and performance.
 * Each locality will create its own copy of the tree
 * Each locality will start with some (unsorted) set of the S/T locations
 * First, each locality will create a uniform tree to a certain level,
   partitioning the particles owned into the maximum level.
 * Then, each will share the counts of particles at those max level nodes
   with all other localities.
 * The totals will then be used to perform a rough split of those nodes with
   among the localities. This algorithm will be deterministic, so that each
   locality will compute the same distribution.
 * Then each locality will send their exported particles to the correct
   locality.
 * At each locality, when all have arrived, the branches of the tree are
   refined to the limit.
 * Then, each locality will share the list of leaves with all other localities.
 * Each locality ends up with the same tree built in local memory, though only
   certain S/T are local.

At this point, each tree can then build a DAG locally using the user's selected
Method.

Then, each locality can then use the selected Distribution policy to compute
the localities of the nodes of the DAG (this will be only the non-terminal
DAG nodes).

Then, each locality can create those LCOs that are owned by that locality and
can then populate the relevant edge information. DAG nodes that are remote
would be given HPX_THERE(loc) as an address.

Then each locality can setup the dependent out edge actions.

Then each locality can start the work on the sources it owns.

The out edge spawn action will have to be ready to either do the current thing,
or send an action to the remote locality that will first look up the address
before doing the set. This remote action should continue the result of the
lookup back to the original LCO where an action will get the user data, and
update the line in the out edge table inside the LCO.
  NOTE: The return should only happen if the DAG is going to be reused.
        Otherwise, this is overkill.
  NOTE: This creates a possible problem for the termination detection. If the
        LCOs start to get deleted on the last iteration, a return message
        could arrive at a destroyed LCO. This bears some thinking.



THE NEW ARRAY

The new layout for Array is going to be through a cyclic allocation of
meta data, and then each local segment implemented as a single block in GAS.

Each record in the cyclic meta data will have the GAS address of the local
part of the data, the number of local records, the number of records, and
the size of the record in bytes. Two of these are constant over the localities,
but to keep extra copies is not a terrible burden.

The array should support the same main operations, but the get and put should
perhaps get and put on a rank by rank basis. That is how the user will use the
thing in any event, so why not bake it into the interface. And then, if the
user wishes, they can go ahead and only load on one rank or so on.
  Though, this will complicate the error comparison thing...

The array should also get a new method that will perform a sort over the local
data blocks according to some criterion. Not sure how we should specify it, but
basically it is a map from the record to an integer that gives the ordering.
Having multiple records with the same sort order is fine.
  Perhaps this first runs by and labels the records, and then orders them
  after that. Knowing the bin in that way I think allows for a pretty okay
  sort to happen. Especially given that this is not a comparison sort. Really
  this is a grouping operation.

  This would mutate the array in place.

Then there would be a second operation that creates a new distributed sort of
  the data. This would create a new array. Even if only internally before
  returning the new thing to the user.


I think array ref does not need to change. It can only refer to data in a local
chunk. So an array ref that spans localities is not possible.




DO THESE THINGS
 * include
   - dashmm
  D : array.h
        Largely speaking, the interface should not change too much for this.
        The existing things will still be needed when fully distributed, but
        their implementation should likely change. Further, we shall need to
        extend the interface with some new things, even if only for internal
        user.
  D : arraymapaction.h
        Once again, to the extent possible, this should keep its interface.
        Once again, the implementation will need to be updated.
  D : arraymetadata.h
        This will need to change, but those are tied in with the overall change
        to how the Array works internally.
  D : arrayref.h
        This too will need to change. The distribution of the data will mean
        that this will have to become more complicated.
            This is actually just as it was, but the reference now can only
            apply to the data at a single locality. Revisit if more is needed.
            But I don't think it will be.
    : evaluator.h
        There is some work needed for dealing with the source references that
        will need to wait on working out Array, but mostly this is written
        at a higher level. So this should be pretty easy to get ready. One
        good place to start here would be to start defining the broken down
        API for the evaluation. Then we can just use that.
    : expansionlco.h
      D * to be able to handle resets, we do not want to explicitly copy the
          out edge record stuff, even though currently nothing was provided
          there. When it is reset, we do not want the existing information
          in the out edges to be scrubbed.
      D * We shall need to add an "empty" set out edge data mode for the set
          operation. This is for subsequent uses. Probably extend
          set_out_edge_data with a boolean to indicate reset or not.
        * The spawn_out_edges_handler will need to detect if the edge data
          is just the HPX_THERE address and send the result to the correct
          locality where it might look up the correct global address.
          Though, the work will likely be complete on the sender side still as
          we will have access to the indices and so on.
            This has to wait on the new style of tree creation, the simple
            early distribution will know all addresses from the start.
      D * We also want to send the expansion data across the network only a
          single time for each locality. So we want to first sort the out edges
          by the target locality. Then the expansion data is sent across the
          network. At the far side it will go ahead and perform the translations
          and then the local lco sets. -- further, the ->T operations should
          be performed last
              Okay - sorting is done
              This is implemented, but is not tested. Currently, there is no
              distribution possible. Perhaps I will get everything ready,
              and then run with some nonsense distribution just to test it.
  D : targetlco.h
        The change in Array and ArrayRef will impact here also.
        Otherwise, this should be fine provided the LCO is always colocated
        with the Target data it is representing.

        Actually, this might not change that much, if at all. I think the
        same interface on the reference means this does not need any update.
        It is only in things that create ArrayRef from an Array that needs to
        worry about the change.
    : tree.h
        * The array reference type will impact this.
      D * The tree will no longer partition at the same time as it generates
          the DAG.
        * Largely speaking, the tree is still going to live in local memory. It
          is just that there are stages in the construction when the various
          trees speak with one another.
        * So yeah, this is likely to change significantly. I think I should
          first work out how the interface will want to look. And then go from
          there.
      D * For the spawn of the S->?, we want to sort the out edges by locality
          and send to each locality only once, and then do the set of edges
          on the far side. Further, the ->T operations should be performed last
              Okay - sorting is done

              This one is not as clean. This can be rearranged so that the
              sources are sent to each locality only once, but is that a win
              compared to setting the expansion? If there are lots of edges
              then this is a win. But otherwise, it might not be.

              S->M should never be remote, so that is not really a concern
              S->L could very well be remote. So perhaps we just make sure
              that we do not multiple send the sources to the same locality
              for S->T operations?
 * src
  D : array.cc
        This whole thing will need an update. We do not yet have the Array
        implementation worked out for the distributed case. There is likely to
        be significant change to how it works internally.



THIS BRANCH TODO

TODO: clean up code where possible
TODO: create test case for new ViewSet stuff? Or just do the real thing and
      have done with it.
TODO: We need to update the comments in the dag.h file.

TODO: decide if I want to add assertions around the calls to the Expansion
      operations to make sure the Expansion Role is correct.

TODO: We are pretty inconsistent about the use of int vs size_t. Work out what
      to do about this.
          Basically, leave it better than you found it.
        - One place this is annoying is in the 'other_member' member of dag
          nodes. At the moment, we use the larger size there, and case to
          integers for the accuracy.
TODO: Improve the way that we optionally put out the DAG information. Perhaps
      this would be another version of evaluate, but which takes an additional
      template parameter serving the DAG output. This would then force the
      factorization of evaluate even higher.
        Or perhaps once there is a mechanism to get the DAG for a given
        evaluation, we can just go ahead and return that the user, and they
        can call whatever methods they want on it.
TODO: create standard regression and performance testing script to determine
      quality of a build.
TODO: Decide if we should move setup_termination_detection, setup_edge_lists
      and destroy_DAG_LCOs into evaluator



Overall Plan to 1.0

 * DONE Split DAG from Tree
 * Make intermediate expansions possible
    This is provisionally DONE. This did not break the current operation of
    all existing examples. However, a specific example was not created to test
    this. Instead, the full Merge-And-Shift FMM will be implemented. If there
    are problems, then these can be easily addressed in whatever state the
    code is in.

 * Full distribution of data and work
    - build one locality tree from distributed particle data (and sort those
      particles as needed)
    - Array needs to be updated accordingly (DONE)
    - Introduce more distribution policies

 * Kernel Parameters and Table generation - this is perhaps via another
     method added to the expansion concept. This will be called at a certain
     point during the evaluation (once the domain is available)
 * Split Evaluate into pieces and expose more interface to users
    - Enable repeat use of a DAG
    - Potentially provide objects representing the tree and so on to the user
      and some utility routines to use the resulting objects
 * Finish interface
    - Make it so that an advanced user could call all the needed stuff directly
      from an HPX thread.
    - As a corollary to that, add assertions to routines that have
      inside / outside HPX restrictions
 * Documentation clean up throughout
    - advanced user guide; including how to define methods
    - be sure to be clear about routines callable from HPX or not.
    - actually build the documentation with DoxyGen to see if it is done
    - consider placing the user-facing heads into a different directory than
      the internal stuff
 * As there is time, work on performance
    - Time various parts of the code



OPEN QUESTIONS and TODO
TODO: What is it about HPX-5 that is absolutely needed by DASHMM? Would
      something more specific be better? Can we introduce some abstraction to
      insulate ourselves from the HPX-5 risk?
TODO: Make the Array type work from inside HPX-5 threads also
        (We have no use case for this just yet. Delay)
TODO: Should we explicitly enforce the singleton nature of Evaluator?
        (This is not a bad idea, but it can wait, as long as the docs warn
         users.)
TODO: currently it is impossible to use the same tree for different Evaluators.
      Do we want to decouple the tree?
        (This might be harder to do. The handles to the DAG make the tree for
         one specific evaluation.)
TODO: Perhaps we want to parameterize the nodes with some user data? So
      the user can use the tree for other things as well.
        (Cool idea; no use case. Delay)
TODO: Do we want to decouple the registration from the evaluation? Two objects?
      Some kind of template function?
        (Not sure. It is not too onerous to do as we have been.)
TODO: There is an overdecomposition factor in ArrayMapAction that is hard
      coded. Explore this and pick one that performs well.




Some notes about issues or future features

* We will need to improve the error handling in this thing quite a bit.
Basically any way that the user-facing methods can go wrong should return
sensible error where possible instead of just being assertions that fail.



Interface Ideas

 * Provide C bindings before too long
      (Useful for people stuck back in the day, but might be of little utility.)

 * We should also in the near term get a base nearest neighbor search. This will
   be essential for SPH and Phil's MFV methods.
   This would be useful in much wider contexts, however.
 * Do LaplaceCOM with softened force (ala GADGET)
 * Do one for Ewald technique for periodic BCs
 * Do one for Short range forces

Some more methods

 * Can we do something more like GADGET's BH method?
    (This is more tricky. The acceptability of an expansion is dependent on the
     particle data of the targets. This would make the node-wide analysis
     harder or more conservative than is needed.)
 * Is there some room for performance improvement in BH where we might use
   single particles for the decision? Is this just a matter of using a smaller
   threshold? Will that pay any dividends?
