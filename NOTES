THIS BRANCH TODO


TODO: Clean up dualtree.h
      remove whatever possible from that into the evaluator object.
      ---> Would that remove the Expansion and Method template arguments?
           That would be nice.

TODO: Also update naming scheme of non static class members (lots of these)

TODO: Change distropolicy_t to work like the serializer does now.

TODO: Make stuff sent to expansion_t const where possible.



==========================================
Things that likely would not break the API
==========================================

TODO: Decide if there is a better solution to the access to tree node problem
      that has cropped up for DAGInfo.
TODO: The remote stuff should be an RDMA into a preallocated buffer. At least,
      this would allow a no-copy spawn of the remote edges.

TODO: Decide if the current solution for the DAG vector capacity problem is
      good enough, or if we should instead work toward collecting the tree
      sizes.
TODO: This is likely the big limiter in the short term on problem size. We
      need to improve the memory use of the explicit DAG. If there were a way
      to perhaps clean that up before we really begin the execution that would
      be awesome, or to start to delete it when it begins. But there is a good
      deal of waste and repetition there. The fact of the explicit DAG is nice,
      but it needs to be made more efficient.
          There has been some work on this, and I am not sure if there is not
          more we can do. Take a look, and if we have basically done it, we
          should just go ahead and remove this item from this list.
TODO: Think about if there are places that RDMA could improve the performance.
      That might have us putting more into the GAS.
TODO: be more clear about when an expansion needs to own data and when not.
TODO: Inside expansionlco.h, we do a forward declaration of DualTree. This seems
      like an inelegant solution, and perhaps one that relies on the
      inclusion order. Check into this.
TODO: From tree.h line 2240
    // TODO: This is an inelegant solution to the problem of getting the
    // local segments unpinned. src_data and trg_data will unpin the segment
    // when the scope we introduce here is closed. Perhaps add unpin(), but
    // that detracts from the RAII nature of the current ArrayData object.


Related to REU Work
-----------------------
TODO: Test Drake's other ideas and code for the distribution. Merge the best
      into dev-v2.
      ---> probably make the unif node distribution all be classes that derive
           from some abstract base. And then let the user supply an instance
           that they want to use, and have some suitable default.
TODO: Start to isolate backend inside DASHMM. Integrate BARIUM


Software Engineering/Good Practice Related
------------------------------------------
TODO: Update INSTALL for the fact of cmake
TODO: Work out the cpack stuff for the build system
TODO: We are pretty inconsistent about the use of int vs size_t. Work out what
      to do about this.
          Basically, leave it better than you found it.
        - One place this is annoying is in the 'other_member' member of dag
          nodes. At the moment, we use the larger size there, and case to
          integers for the accuracy.
TODO: create standard regression and performance testing script to determine
      quality of a build.
TODO: Finish interface
    - Make it so that an advanced user could call all the needed stuff directly
      from an HPX thread. <----- THIS ONE MAY BE MORE IMPORTANT THAN IT WAS
    - As a corollary to that, add assertions to routines that have
      inside / outside HPX restrictions
TODO: The expansion concept does not allow for access of the kernel parameters.
   They end up in the table, and cannot be accessed later. Not sure if this is
   a problem, but it could be.
TODO: Another idea from Bo: Store the edges in one place and then just index
      into that. Cuts down on the representation by quite a bit.
TODO: FORTRAN skeleten Expansion. Somehow link to a user's existing FORTRAN
      operations.

========================================
Things that definitely would break the API
========================================

TODO: Make the way that Expansions manage their data not suck as much as it
      does now. Really. There is a strange complicated dance happening with
      all of this, and it will be easy for a user to muck it up.
TODO: ViewSet is not something I particularly like. See if there is a way to
  make this less awful. (This is basically the same as above)
TODO: Work out if there is a better way to apply the distribution. We shall
      need to have some way to parallelize it, or have some way to overlap that
      work with other work.
        Perhaps have a second pass with the same sort of tree parallel thing
        like when the DAG is discovered.
TODO: Perhaps we want to parameterize the nodes with some user data? So
      the user can use the tree for other things as well.
  * It would be nice if we were to decouple some of the use of the tree and the
  construction of the tree. The ultimate goal would be to perhaps allow the
  user to supply their tree to us, like if they had a better method to make
  it, or if their code already needs to make a tree for some reason. Then
  DASHMM could just do the DAG and so on. This would also allow us to try
  other constructions more easily. We basically would be able to hot swap
  implementations. Also, this might make it simpler to make a tree that can
  update adiabadically.








FUTURE BUILT-INs
 * We should also in the near term get a base nearest neighbor search. This
   will be essential for SPH and Phil's MFV methods.
   This would be useful in much wider contexts, however.
 * Do LaplaceCOM with softened force (ala GADGET)
 * Do one for Ewald technique for periodic BCs
 * Do one for Short range forces
 * Can we do something more like GADGET's BH method?
    (This is more tricky. The acceptability of an expansion is dependent on the
     particle data of the targets. This would make the node-wide analysis
     harder or more conservative than is needed.)
 * Is there some room for performance improvement in BH where we might use
   single particles for the decision? Is this just a matter of using a smaller
   threshold? Will that pay any dividends?



IDEAS TO TRY
  * If we get the tree decoupled from the execution, could we perhaps use
    GADGET or AREPO or GIZMO or whatever to build the tree, and then just sub
    in our execution? That would be a pretty damn good comparison to make.
    It would mean that design of our decoupling would need to be such that
    we could do this. But that would be a really cool comparison to make.
    Really cool.
