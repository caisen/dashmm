THIS BRANCH TODO


TODO: The merger of the treebuild3 has created somewhat of a monster. That
  really ought to be sorted out. It is pretty gnarly, and the code is at
  a high risk of being hard to maintain.


TODO: Think about the following issue
  The out edge spawn action will have to be ready to either do the current thing,
  or send an action to the remote locality that will first look up the address
  before doing the set. This remote action should continue the result of the
  lookup back to the original LCO where an action will get the user data, and
  update the line in the out edge table inside the LCO.
    NOTE: The return should only happen if the DAG is going to be reused.
          Otherwise, this is overkill.
    NOTE: This creates a possible problem for the termination detection. If the
          LCOs start to get deleted on the last iteration, a return message
          could arrive at a destroyed LCO. This bears some thinking.
TODO: Deal with the return messages about the addresses of the remote LCOs
    (Do we even want to do this? There is an issue with termination detection
     here.)

TODO: Consider changing ExpansionLCO to only contain the needed info from the
    DomainGeometry. The use is very simple, getting box sizes and so on.


TODO: Remove the offset in the array map action.

TODO: Allow for the array map action to have a couple integer template
      parameters. One to indicate the overdecomposition. The other to indicate
      how many threads should deal with each segment.

TODO: be more clear about when an expansion needs to own data and when not.
TODO: clean up code where possible
TODO: In tree, privatize anything possible
TODO: The same is true everywhere I guess.
TODO: We need to update the comments throughout

TODO: decide if I want to add assertions around the calls to the Expansion
      operations to make sure the Expansion Role is correct.

TODO: We are pretty inconsistent about the use of int vs size_t. Work out what
      to do about this.
          Basically, leave it better than you found it.
        - One place this is annoying is in the 'other_member' member of dag
          nodes. At the moment, we use the larger size there, and case to
          integers for the accuracy.
TODO: Improve the way that we optionally put out the DAG information. Perhaps
      this would be another version of evaluate, but which takes an additional
      template parameter serving the DAG output. This would then force the
      factorization of evaluate even higher.
        Or perhaps once there is a mechanism to get the DAG for a given
        evaluation, we can just go ahead and return that the user, and they
        can call whatever methods they want on it.
TODO: create standard regression and performance testing script to determine
      quality of a build.
TODO: Decode if we should also test Hilbert ordering on the top level distrib
      of the tree. This might have some better locality.
TODO: Further, should we allow for a non-space-filling curve distribution.
      This might be a way to make a non-contiguous chunk on the SFC a better
      overall distribution.
TODO: separate the include directories into dashmm and libdashmm, patterned
      after HPX. This will make it 'clear' which are to be used by the casual
      user, and which are not part of the public interface. This will also be
      important for dealing with a complete specification.
TODO: Recall that the usage pattern of the DAG routines will want to change
      if we ever have multiple threads working on a single node for the DAG.
      That might not be likely, but it bears some more careful thought.



Overall Plan to 1.0
 * Full distribution of data and work
    - build one locality tree from distributed particle data (and sort those
      particles as needed)
    - Array needs to be updated accordingly (DONE)
    - Introduce more distribution policies

 * Documentation clean up throughout
    - advanced user guide; including how to define methods
    - be sure to be clear about routines callable from HPX or not.
    - actually build the documentation with DoxyGen to see if it is done
    - consider placing the user-facing heads into a different directory than
      the internal stuff

 * Decide if we are changing the license
    - Look into GPL vs LGPL
    - Doublecheck with Bo that he is still down
    - Update all files everywhere

 * Split Evaluate into pieces and expose more interface to users
    - NOTE: This is not a vital thing to accomplish for 1.0.0
    - Enable repeat use of a DAG
    - Potentially provide objects representing the tree and so on to the user
      and some utility routines to use the resulting objects
 * Finish interface
    - NOTE: this is not a vital thing to accomplish for 1.0.0
    - Make it so that an advanced user could call all the needed stuff directly
      from an HPX thread.
    - As a corollary to that, add assertions to routines that have
      inside / outside HPX restrictions
 * As there is time, work on performance
    - Time various parts of the code



OPEN QUESTIONS and TODO
TODO: What is it about HPX-5 that is absolutely needed by DASHMM? Would
      something more specific be better? Can we introduce some abstraction to
      insulate ourselves from the HPX-5 risk?
TODO: Make the Array type work from inside HPX-5 threads also
        (We have no use case for this just yet. Delay)
        (Also, think about adding the two kinds of sorting to the Array.
         at the moment, there is not really any use case in mind, other than
         wouldn't it be nice. So we can delay this until we need it.)
TODO: Should we explicitly enforce the singleton nature of Evaluator?
        (This is not a bad idea, but it can wait, as long as the docs warn
         users.)
TODO: currently it is impossible to use the same tree for different Evaluators.
      Do we want to decouple the tree?
        (This might be harder to do. The handles to the DAG make the tree for
         one specific evaluation.)
TODO: Perhaps we want to parameterize the nodes with some user data? So
      the user can use the tree for other things as well.
        (Cool idea; no use case. Delay)
TODO: There is an overdecomposition factor in ArrayMapAction that is hard
      coded. Explore this and pick one that performs well.




Some notes about issues or future features

* We will need to improve the error handling in this thing quite a bit.
Basically any way that the user-facing methods can go wrong should return
sensible error where possible instead of just being assertions that fail.



Interface Ideas

 * We should also in the near term get a base nearest neighbor search. This will
   be essential for SPH and Phil's MFV methods.
   This would be useful in much wider contexts, however.
 * Do LaplaceCOM with softened force (ala GADGET)
 * Do one for Ewald technique for periodic BCs
 * Do one for Short range forces

Some more methods

 * Can we do something more like GADGET's BH method?
    (This is more tricky. The acceptability of an expansion is dependent on the
     particle data of the targets. This would make the node-wide analysis
     harder or more conservative than is needed.)
 * Is there some room for performance improvement in BH where we might use
   single particles for the decision? Is this just a matter of using a smaller
   threshold? Will that pay any dividends?
